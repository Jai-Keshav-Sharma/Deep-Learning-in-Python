{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ue_1HaUxLajE"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"Q 1. What is the reason for these Cyber Security Directions?\n",
        "Ans: The Internet in India is growing fast and over the next few years over 120 Crore\n",
        "Indians will have access to the Internet and use it for business, education, finance and\n",
        "myriad other applications and services including Digital Government services. The\n",
        "Internet has seen growth in innovation and at the same time it has seen rise in crimes,\n",
        "user harm and other challenges to online safety. It is the Government of India’s policy\n",
        "goal to ensure that Indian Internet users experience a Safe & Trusted Internet. Cyber\n",
        "Security Directions are a part of the overall framework of ensuring online safety and\n",
        "trust for users.\n",
        "Q 2. What is CERT-In and what is the status of CERT-In?\n",
        "Ans.: ‘Indian Computer Emergency Response Team’ (CERT-In) is the national agency\n",
        "for cyber security incident response and proactive measures for prevention of cyber\n",
        "incidents in the Country. CERT-In has been appointed by Central Government vide\n",
        "notification dated 27th October 2009 in terms of the provisions of section 70B (1) of The\n",
        "Information Technology Act, 2000 (IT Act, 2000).\n",
        "Q 3. What is Cyber Security Incident?\n",
        "Ans.: “Cyber Security Incident” means any real or suspected adverse event in relation\n",
        "to cyber security that violates an explicitly or implicitly applicable security policy\n",
        "resulting in unauthorised access, denial of service or disruption, unauthorised use of a\n",
        "computer resource for processing or storage of information or changes in data,\n",
        "information without authorisation.\n",
        "Q 4. Why Cyber Security is important?\n",
        "Ans.: The digital technology and usage of internet has grown exponentially and is\n",
        "integral part of modern life. Today, cyberspace is the common platform used by citizens,\n",
        "businesses and Governments for communication, dissemination of information,\n",
        "e-commerce, services, economic activities, education, entertainment etc. At the same\n",
        "time, the advancement of technology has opened vulnerabilities for exploitation by the\n",
        "malicious actors. Cyber security is the protection of electronic data and information. To\n",
        "deal with the emerging cyber threat landscape and to ensure safe usage of digital\n",
        "technologies by users, the legal, technical, organizational and collaborative measures\n",
        "need to be taken by stakeholders.\n",
        "Q 5. What process was followed to arrive at the Cyber Security Directions of\n",
        "28.04.2022?\n",
        "Ans.: CERT-In is in operation since the year 2004. Based on analysis of cyber security\n",
        "incidents and trends certain gaps in processes of organisations and service providers\n",
        "have been observed by CERT-In. Accordingly, consultations with the industry and\n",
        "Government organisations have been held from time to time and based upon the inputs\n",
        "received from the stakeholders, draft directions were framed. Subsequently, CERT-In\n",
        "under the aegis of MeitY held stakeholder consultation in March 2022 towards\n",
        "finalisation of the directions.\n",
        "Q 6. What are the functions of CERT-In in the area of cyber security?\n",
        "Ans.: CERT-In performs the statutory functions in the area of Cyber Security as\n",
        "specified in sub-section (4) of section 70B of the Information Technology Act, 2000,\n",
        "which enshrines that CERT-In shall serve as the national agency for performing the\n",
        "following functions in the area of cyber security :-\n",
        "a) collection, analysis and dissemination of information on cyber incidents;\n",
        "b) forecast and alerts of cyber security incidents;\n",
        "c) emergency measures for handling cyber security incidents;\n",
        "d) coordination of cyber incident response activities;\n",
        "e) issue guidelines, advisories, vulnerability notes and whitepapers relating to\n",
        "information security practices, procedures, prevention, response and reporting of\n",
        "cyber incidents;\n",
        "f) such other functions relating to cyber security as may be prescribed.\n",
        "Q 7. Who do these Cyber Security Directions of 28.04.2022 apply to?\n",
        "Ans.: Service providers, intermediaries, data centres, body corporate, Virtual Private\n",
        "Server (VPS) providers, Cloud service providers , VPN Service providers, virtual asset\n",
        "service providers, virtual asset exchange providers, custodian wallet providers and\n",
        "Government organisations shall follow these Cyber Security Directions of 28.4.2022 as\n",
        "applicable to them. Individual citizens are not covered by these Directions.\n",
        "Q 10. The Information Technology (Intermediary Guidelines and Digital Media\n",
        "Ethics Code) Rules, 2021 provide that “The intermediary shall report cyber security\n",
        "incidents and also share cyber security incidents related information with the Indian\n",
        "Computer Emergency Response Team”. Do intermediaries have to mandatorily\n",
        "report any and all cyber security incidents or only those specified in the Annexure\n",
        "to the Rules?\n",
        "Ans.: It is correct that the intermediaries as defined under the Information Technology\n",
        "Act and Rules made thereunder to report cyber security incidents and share any related\n",
        "information thereof with CERT-In. The Rule 3(1) (l) of the Information Technology\n",
        "(Intermediary Guidelines and Digital Media Ethics Code) Rules, 2021 provides that\n",
        "“The intermediary shall report cyber security incidents and share related information\n",
        "with the Indian Computer Emergency Response Team in accordance with the policies\n",
        "and procedures as mentioned in the Information Technology (The Indian Computer\n",
        "Emergency Response Team and Manner of Performing Functions and Duties) Rules,\n",
        "2013”. In this context, it is obligatory to note that in terms of Rule 12 of the CERT-In\n",
        "Rules 2013, the type of cyber security incidents as identified in the Annexure [of the\n",
        "Rules] and also brought out in the Cyber Security Directions of 28.04.2022, are to be\n",
        "mandatorily reported to CERT-In by any organization or corporate entity, including\n",
        "intermediaries affected by cyber security incidents as early as possible to leave scope for\n",
        "action.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "2E2XSwDTOu47"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "eM-_fTcKO273"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "cP40bQuQO6X4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE7k_l6vO9S0",
        "outputId": "5ecdaece-a2fe-497c-f445-3856f1455546"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'of': 2,\n",
              " 'in': 3,\n",
              " 'and': 4,\n",
              " 'cyber': 5,\n",
              " 'security': 6,\n",
              " 'to': 7,\n",
              " 'information': 8,\n",
              " 'is': 9,\n",
              " 'cert': 10,\n",
              " 'incidents': 11,\n",
              " 'for': 12,\n",
              " 'directions': 13,\n",
              " 'by': 14,\n",
              " 'as': 15,\n",
              " 'q': 16,\n",
              " 'ans': 17,\n",
              " 'technology': 18,\n",
              " 'providers': 19,\n",
              " 'that': 20,\n",
              " 'response': 21,\n",
              " 'or': 22,\n",
              " 'rules': 23,\n",
              " 'what': 24,\n",
              " 'internet': 25,\n",
              " 'it': 26,\n",
              " 'service': 27,\n",
              " 'with': 28,\n",
              " 'digital': 29,\n",
              " 'government': 30,\n",
              " 'has': 31,\n",
              " 'computer': 32,\n",
              " 'emergency': 33,\n",
              " '2022': 34,\n",
              " 'functions': 35,\n",
              " 'these': 36,\n",
              " 'have': 37,\n",
              " 'time': 38,\n",
              " 'indian': 39,\n",
              " 'a': 40,\n",
              " 'are': 41,\n",
              " 'act': 42,\n",
              " 'any': 43,\n",
              " '28': 44,\n",
              " 'shall': 45,\n",
              " 'intermediaries': 46,\n",
              " 'intermediary': 47,\n",
              " 'report': 48,\n",
              " '1': 49,\n",
              " 'other': 50,\n",
              " 'services': 51,\n",
              " 'at': 52,\n",
              " 'users': 53,\n",
              " 'incident': 54,\n",
              " 'measures': 55,\n",
              " 'been': 56,\n",
              " 'section': 57,\n",
              " '2000': 58,\n",
              " 'data': 59,\n",
              " '4': 60,\n",
              " 'be': 61,\n",
              " '04': 62,\n",
              " 'organisations': 63,\n",
              " 'area': 64,\n",
              " 'guidelines': 65,\n",
              " 'virtual': 66,\n",
              " 'share': 67,\n",
              " 'related': 68,\n",
              " 'over': 69,\n",
              " 'access': 70,\n",
              " 'use': 71,\n",
              " 'education': 72,\n",
              " 'including': 73,\n",
              " 'seen': 74,\n",
              " 'same': 75,\n",
              " 'online': 76,\n",
              " 'safety': 77,\n",
              " 'policy': 78,\n",
              " 'ensure': 79,\n",
              " 'safe': 80,\n",
              " 'part': 81,\n",
              " 'national': 82,\n",
              " 'agency': 83,\n",
              " 'prevention': 84,\n",
              " 'terms': 85,\n",
              " '70b': 86,\n",
              " '3': 87,\n",
              " 'applicable': 88,\n",
              " 'unauthorised': 89,\n",
              " 'usage': 90,\n",
              " 'citizens': 91,\n",
              " 'dissemination': 92,\n",
              " 'e': 93,\n",
              " 'activities': 94,\n",
              " 'stakeholders': 95,\n",
              " 'based': 96,\n",
              " 'on': 97,\n",
              " 'analysis': 98,\n",
              " 'held': 99,\n",
              " 'from': 100,\n",
              " 'under': 101,\n",
              " 'specified': 102,\n",
              " 'performing': 103,\n",
              " 'relating': 104,\n",
              " 'procedures': 105,\n",
              " 'do': 106,\n",
              " 'corporate': 107,\n",
              " 'asset': 108,\n",
              " 'media': 109,\n",
              " 'ethics': 110,\n",
              " 'code': 111,\n",
              " '2021': 112,\n",
              " '“the': 113,\n",
              " 'also': 114,\n",
              " 'mandatorily': 115,\n",
              " 'annexure': 116,\n",
              " 'rule': 117,\n",
              " 'team': 118,\n",
              " 'reason': 119,\n",
              " 'india': 120,\n",
              " 'growing': 121,\n",
              " 'fast': 122,\n",
              " 'next': 123,\n",
              " 'few': 124,\n",
              " 'years': 125,\n",
              " '120': 126,\n",
              " 'crore': 127,\n",
              " 'indians': 128,\n",
              " 'will': 129,\n",
              " 'business': 130,\n",
              " 'finance': 131,\n",
              " 'myriad': 132,\n",
              " 'applications': 133,\n",
              " 'growth': 134,\n",
              " 'innovation': 135,\n",
              " 'rise': 136,\n",
              " 'crimes': 137,\n",
              " 'user': 138,\n",
              " 'harm': 139,\n",
              " 'challenges': 140,\n",
              " 'india’s': 141,\n",
              " 'goal': 142,\n",
              " 'experience': 143,\n",
              " 'trusted': 144,\n",
              " 'overall': 145,\n",
              " 'framework': 146,\n",
              " 'ensuring': 147,\n",
              " 'trust': 148,\n",
              " '2': 149,\n",
              " 'status': 150,\n",
              " '‘indian': 151,\n",
              " 'team’': 152,\n",
              " 'proactive': 153,\n",
              " 'country': 154,\n",
              " 'appointed': 155,\n",
              " 'central': 156,\n",
              " 'vide': 157,\n",
              " 'notification': 158,\n",
              " 'dated': 159,\n",
              " '27th': 160,\n",
              " 'october': 161,\n",
              " '2009': 162,\n",
              " 'provisions': 163,\n",
              " '“cyber': 164,\n",
              " 'incident”': 165,\n",
              " 'means': 166,\n",
              " 'real': 167,\n",
              " 'suspected': 168,\n",
              " 'adverse': 169,\n",
              " 'event': 170,\n",
              " 'relation': 171,\n",
              " 'violates': 172,\n",
              " 'an': 173,\n",
              " 'explicitly': 174,\n",
              " 'implicitly': 175,\n",
              " 'resulting': 176,\n",
              " 'denial': 177,\n",
              " 'disruption': 178,\n",
              " 'resource': 179,\n",
              " 'processing': 180,\n",
              " 'storage': 181,\n",
              " 'changes': 182,\n",
              " 'without': 183,\n",
              " 'authorisation': 184,\n",
              " 'why': 185,\n",
              " 'important': 186,\n",
              " 'grown': 187,\n",
              " 'exponentially': 188,\n",
              " 'integral': 189,\n",
              " 'modern': 190,\n",
              " 'life': 191,\n",
              " 'today': 192,\n",
              " 'cyberspace': 193,\n",
              " 'common': 194,\n",
              " 'platform': 195,\n",
              " 'used': 196,\n",
              " 'businesses': 197,\n",
              " 'governments': 198,\n",
              " 'communication': 199,\n",
              " 'commerce': 200,\n",
              " 'economic': 201,\n",
              " 'entertainment': 202,\n",
              " 'etc': 203,\n",
              " 'advancement': 204,\n",
              " 'opened': 205,\n",
              " 'vulnerabilities': 206,\n",
              " 'exploitation': 207,\n",
              " 'malicious': 208,\n",
              " 'actors': 209,\n",
              " 'protection': 210,\n",
              " 'electronic': 211,\n",
              " 'deal': 212,\n",
              " 'emerging': 213,\n",
              " 'threat': 214,\n",
              " 'landscape': 215,\n",
              " 'technologies': 216,\n",
              " 'legal': 217,\n",
              " 'technical': 218,\n",
              " 'organizational': 219,\n",
              " 'collaborative': 220,\n",
              " 'need': 221,\n",
              " 'taken': 222,\n",
              " '5': 223,\n",
              " 'process': 224,\n",
              " 'was': 225,\n",
              " 'followed': 226,\n",
              " 'arrive': 227,\n",
              " 'operation': 228,\n",
              " 'since': 229,\n",
              " 'year': 230,\n",
              " '2004': 231,\n",
              " 'trends': 232,\n",
              " 'certain': 233,\n",
              " 'gaps': 234,\n",
              " 'processes': 235,\n",
              " 'observed': 236,\n",
              " 'accordingly': 237,\n",
              " 'consultations': 238,\n",
              " 'industry': 239,\n",
              " 'upon': 240,\n",
              " 'inputs': 241,\n",
              " 'received': 242,\n",
              " 'draft': 243,\n",
              " 'were': 244,\n",
              " 'framed': 245,\n",
              " 'subsequently': 246,\n",
              " 'aegis': 247,\n",
              " 'meity': 248,\n",
              " 'stakeholder': 249,\n",
              " 'consultation': 250,\n",
              " 'march': 251,\n",
              " 'towards': 252,\n",
              " 'finalisation': 253,\n",
              " '6': 254,\n",
              " 'performs': 255,\n",
              " 'statutory': 256,\n",
              " 'sub': 257,\n",
              " 'which': 258,\n",
              " 'enshrines': 259,\n",
              " 'serve': 260,\n",
              " 'following': 261,\n",
              " 'collection': 262,\n",
              " 'b': 263,\n",
              " 'forecast': 264,\n",
              " 'alerts': 265,\n",
              " 'c': 266,\n",
              " 'handling': 267,\n",
              " 'd': 268,\n",
              " 'coordination': 269,\n",
              " 'issue': 270,\n",
              " 'advisories': 271,\n",
              " 'vulnerability': 272,\n",
              " 'notes': 273,\n",
              " 'whitepapers': 274,\n",
              " 'practices': 275,\n",
              " 'reporting': 276,\n",
              " 'f': 277,\n",
              " 'such': 278,\n",
              " 'may': 279,\n",
              " 'prescribed': 280,\n",
              " '7': 281,\n",
              " 'who': 282,\n",
              " 'apply': 283,\n",
              " 'centres': 284,\n",
              " 'body': 285,\n",
              " 'private': 286,\n",
              " 'server': 287,\n",
              " 'vps': 288,\n",
              " 'cloud': 289,\n",
              " 'vpn': 290,\n",
              " 'exchange': 291,\n",
              " 'custodian': 292,\n",
              " 'wallet': 293,\n",
              " 'follow': 294,\n",
              " 'them': 295,\n",
              " 'individual': 296,\n",
              " 'not': 297,\n",
              " 'covered': 298,\n",
              " '10': 299,\n",
              " 'provide': 300,\n",
              " 'team”': 301,\n",
              " 'all': 302,\n",
              " 'only': 303,\n",
              " 'those': 304,\n",
              " 'correct': 305,\n",
              " 'defined': 306,\n",
              " 'made': 307,\n",
              " 'thereunder': 308,\n",
              " 'thereof': 309,\n",
              " 'l': 310,\n",
              " 'provides': 311,\n",
              " 'accordance': 312,\n",
              " 'policies': 313,\n",
              " 'mentioned': 314,\n",
              " 'manner': 315,\n",
              " 'duties': 316,\n",
              " '2013”': 317,\n",
              " 'this': 318,\n",
              " 'context': 319,\n",
              " 'obligatory': 320,\n",
              " 'note': 321,\n",
              " '12': 322,\n",
              " '2013': 323,\n",
              " 'type': 324,\n",
              " 'identified': 325,\n",
              " 'brought': 326,\n",
              " 'out': 327,\n",
              " 'reported': 328,\n",
              " 'organization': 329,\n",
              " 'entity': 330,\n",
              " 'affected': 331,\n",
              " 'early': 332,\n",
              " 'possible': 333,\n",
              " 'leave': 334,\n",
              " 'scope': 335,\n",
              " 'action': 336}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "XA6ZRLRNO_O5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating the input data\n",
        "\n",
        "input_sequences = []\n",
        "\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "p0X_cFapPfWK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6-ltHhIQPlmj",
        "outputId": "f162f44f-3cd1-47db-a076-a7e37ec3ee86"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[16, 49],\n",
              " [16, 49, 24],\n",
              " [16, 49, 24, 9],\n",
              " [16, 49, 24, 9, 1],\n",
              " [16, 49, 24, 9, 1, 119],\n",
              " [16, 49, 24, 9, 1, 119, 12],\n",
              " [16, 49, 24, 9, 1, 119, 12, 36],\n",
              " [16, 49, 24, 9, 1, 119, 12, 36, 5],\n",
              " [16, 49, 24, 9, 1, 119, 12, 36, 5, 6],\n",
              " [16, 49, 24, 9, 1, 119, 12, 36, 5, 6, 13],\n",
              " [17, 1],\n",
              " [17, 1, 25],\n",
              " [17, 1, 25, 3],\n",
              " [17, 1, 25, 3, 120],\n",
              " [17, 1, 25, 3, 120, 9],\n",
              " [17, 1, 25, 3, 120, 9, 121],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122, 4],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122, 4, 69],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122, 4, 69, 1],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122, 4, 69, 1, 123],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122, 4, 69, 1, 123, 124],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122, 4, 69, 1, 123, 124, 125],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122, 4, 69, 1, 123, 124, 125, 69],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122, 4, 69, 1, 123, 124, 125, 69, 126],\n",
              " [17, 1, 25, 3, 120, 9, 121, 122, 4, 69, 1, 123, 124, 125, 69, 126, 127],\n",
              " [128, 129],\n",
              " [128, 129, 37],\n",
              " [128, 129, 37, 70],\n",
              " [128, 129, 37, 70, 7],\n",
              " [128, 129, 37, 70, 7, 1],\n",
              " [128, 129, 37, 70, 7, 1, 25],\n",
              " [128, 129, 37, 70, 7, 1, 25, 4],\n",
              " [128, 129, 37, 70, 7, 1, 25, 4, 71],\n",
              " [128, 129, 37, 70, 7, 1, 25, 4, 71, 26],\n",
              " [128, 129, 37, 70, 7, 1, 25, 4, 71, 26, 12],\n",
              " [128, 129, 37, 70, 7, 1, 25, 4, 71, 26, 12, 130],\n",
              " [128, 129, 37, 70, 7, 1, 25, 4, 71, 26, 12, 130, 72],\n",
              " [128, 129, 37, 70, 7, 1, 25, 4, 71, 26, 12, 130, 72, 131],\n",
              " [128, 129, 37, 70, 7, 1, 25, 4, 71, 26, 12, 130, 72, 131, 4],\n",
              " [132, 50],\n",
              " [132, 50, 133],\n",
              " [132, 50, 133, 4],\n",
              " [132, 50, 133, 4, 51],\n",
              " [132, 50, 133, 4, 51, 73],\n",
              " [132, 50, 133, 4, 51, 73, 29],\n",
              " [132, 50, 133, 4, 51, 73, 29, 30],\n",
              " [132, 50, 133, 4, 51, 73, 29, 30, 51],\n",
              " [132, 50, 133, 4, 51, 73, 29, 30, 51, 1],\n",
              " [25, 31],\n",
              " [25, 31, 74],\n",
              " [25, 31, 74, 134],\n",
              " [25, 31, 74, 134, 3],\n",
              " [25, 31, 74, 134, 3, 135],\n",
              " [25, 31, 74, 134, 3, 135, 4],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52, 1],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52, 1, 75],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52, 1, 75, 38],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52, 1, 75, 38, 26],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52, 1, 75, 38, 26, 31],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52, 1, 75, 38, 26, 31, 74],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52, 1, 75, 38, 26, 31, 74, 136],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52, 1, 75, 38, 26, 31, 74, 136, 3],\n",
              " [25, 31, 74, 134, 3, 135, 4, 52, 1, 75, 38, 26, 31, 74, 136, 3, 137],\n",
              " [138, 139],\n",
              " [138, 139, 4],\n",
              " [138, 139, 4, 50],\n",
              " [138, 139, 4, 50, 140],\n",
              " [138, 139, 4, 50, 140, 7],\n",
              " [138, 139, 4, 50, 140, 7, 76],\n",
              " [138, 139, 4, 50, 140, 7, 76, 77],\n",
              " [138, 139, 4, 50, 140, 7, 76, 77, 26],\n",
              " [138, 139, 4, 50, 140, 7, 76, 77, 26, 9],\n",
              " [138, 139, 4, 50, 140, 7, 76, 77, 26, 9, 1],\n",
              " [138, 139, 4, 50, 140, 7, 76, 77, 26, 9, 1, 30],\n",
              " [138, 139, 4, 50, 140, 7, 76, 77, 26, 9, 1, 30, 2],\n",
              " [138, 139, 4, 50, 140, 7, 76, 77, 26, 9, 1, 30, 2, 141],\n",
              " [138, 139, 4, 50, 140, 7, 76, 77, 26, 9, 1, 30, 2, 141, 78],\n",
              " [142, 7],\n",
              " [142, 7, 79],\n",
              " [142, 7, 79, 20],\n",
              " [142, 7, 79, 20, 39],\n",
              " [142, 7, 79, 20, 39, 25],\n",
              " [142, 7, 79, 20, 39, 25, 53],\n",
              " [142, 7, 79, 20, 39, 25, 53, 143],\n",
              " [142, 7, 79, 20, 39, 25, 53, 143, 40],\n",
              " [142, 7, 79, 20, 39, 25, 53, 143, 40, 80],\n",
              " [142, 7, 79, 20, 39, 25, 53, 143, 40, 80, 144],\n",
              " [142, 7, 79, 20, 39, 25, 53, 143, 40, 80, 144, 25],\n",
              " [142, 7, 79, 20, 39, 25, 53, 143, 40, 80, 144, 25, 5],\n",
              " [6, 13],\n",
              " [6, 13, 41],\n",
              " [6, 13, 41, 40],\n",
              " [6, 13, 41, 40, 81],\n",
              " [6, 13, 41, 40, 81, 2],\n",
              " [6, 13, 41, 40, 81, 2, 1],\n",
              " [6, 13, 41, 40, 81, 2, 1, 145],\n",
              " [6, 13, 41, 40, 81, 2, 1, 145, 146],\n",
              " [6, 13, 41, 40, 81, 2, 1, 145, 146, 2],\n",
              " [6, 13, 41, 40, 81, 2, 1, 145, 146, 2, 147],\n",
              " [6, 13, 41, 40, 81, 2, 1, 145, 146, 2, 147, 76],\n",
              " [6, 13, 41, 40, 81, 2, 1, 145, 146, 2, 147, 76, 77],\n",
              " [6, 13, 41, 40, 81, 2, 1, 145, 146, 2, 147, 76, 77, 4],\n",
              " [148, 12],\n",
              " [148, 12, 53],\n",
              " [16, 149],\n",
              " [16, 149, 24],\n",
              " [16, 149, 24, 9],\n",
              " [16, 149, 24, 9, 10],\n",
              " [16, 149, 24, 9, 10, 3],\n",
              " [16, 149, 24, 9, 10, 3, 4],\n",
              " [16, 149, 24, 9, 10, 3, 4, 24],\n",
              " [16, 149, 24, 9, 10, 3, 4, 24, 9],\n",
              " [16, 149, 24, 9, 10, 3, 4, 24, 9, 1],\n",
              " [16, 149, 24, 9, 10, 3, 4, 24, 9, 1, 150],\n",
              " [16, 149, 24, 9, 10, 3, 4, 24, 9, 1, 150, 2],\n",
              " [16, 149, 24, 9, 10, 3, 4, 24, 9, 1, 150, 2, 10],\n",
              " [16, 149, 24, 9, 10, 3, 4, 24, 9, 1, 150, 2, 10, 3],\n",
              " [17, 151],\n",
              " [17, 151, 32],\n",
              " [17, 151, 32, 33],\n",
              " [17, 151, 32, 33, 21],\n",
              " [17, 151, 32, 33, 21, 152],\n",
              " [17, 151, 32, 33, 21, 152, 10],\n",
              " [17, 151, 32, 33, 21, 152, 10, 3],\n",
              " [17, 151, 32, 33, 21, 152, 10, 3, 9],\n",
              " [17, 151, 32, 33, 21, 152, 10, 3, 9, 1],\n",
              " [17, 151, 32, 33, 21, 152, 10, 3, 9, 1, 82],\n",
              " [17, 151, 32, 33, 21, 152, 10, 3, 9, 1, 82, 83],\n",
              " [12, 5],\n",
              " [12, 5, 6],\n",
              " [12, 5, 6, 54],\n",
              " [12, 5, 6, 54, 21],\n",
              " [12, 5, 6, 54, 21, 4],\n",
              " [12, 5, 6, 54, 21, 4, 153],\n",
              " [12, 5, 6, 54, 21, 4, 153, 55],\n",
              " [12, 5, 6, 54, 21, 4, 153, 55, 12],\n",
              " [12, 5, 6, 54, 21, 4, 153, 55, 12, 84],\n",
              " [12, 5, 6, 54, 21, 4, 153, 55, 12, 84, 2],\n",
              " [12, 5, 6, 54, 21, 4, 153, 55, 12, 84, 2, 5],\n",
              " [11, 3],\n",
              " [11, 3, 1],\n",
              " [11, 3, 1, 154],\n",
              " [11, 3, 1, 154, 10],\n",
              " [11, 3, 1, 154, 10, 3],\n",
              " [11, 3, 1, 154, 10, 3, 31],\n",
              " [11, 3, 1, 154, 10, 3, 31, 56],\n",
              " [11, 3, 1, 154, 10, 3, 31, 56, 155],\n",
              " [11, 3, 1, 154, 10, 3, 31, 56, 155, 14],\n",
              " [11, 3, 1, 154, 10, 3, 31, 56, 155, 14, 156],\n",
              " [11, 3, 1, 154, 10, 3, 31, 56, 155, 14, 156, 30],\n",
              " [11, 3, 1, 154, 10, 3, 31, 56, 155, 14, 156, 30, 157],\n",
              " [158, 159],\n",
              " [158, 159, 160],\n",
              " [158, 159, 160, 161],\n",
              " [158, 159, 160, 161, 162],\n",
              " [158, 159, 160, 161, 162, 3],\n",
              " [158, 159, 160, 161, 162, 3, 85],\n",
              " [158, 159, 160, 161, 162, 3, 85, 2],\n",
              " [158, 159, 160, 161, 162, 3, 85, 2, 1],\n",
              " [158, 159, 160, 161, 162, 3, 85, 2, 1, 163],\n",
              " [158, 159, 160, 161, 162, 3, 85, 2, 1, 163, 2],\n",
              " [158, 159, 160, 161, 162, 3, 85, 2, 1, 163, 2, 57],\n",
              " [158, 159, 160, 161, 162, 3, 85, 2, 1, 163, 2, 57, 86],\n",
              " [158, 159, 160, 161, 162, 3, 85, 2, 1, 163, 2, 57, 86, 49],\n",
              " [158, 159, 160, 161, 162, 3, 85, 2, 1, 163, 2, 57, 86, 49, 2],\n",
              " [158, 159, 160, 161, 162, 3, 85, 2, 1, 163, 2, 57, 86, 49, 2, 1],\n",
              " [8, 18],\n",
              " [8, 18, 42],\n",
              " [8, 18, 42, 58],\n",
              " [8, 18, 42, 58, 26],\n",
              " [8, 18, 42, 58, 26, 42],\n",
              " [8, 18, 42, 58, 26, 42, 58],\n",
              " [16, 87],\n",
              " [16, 87, 24],\n",
              " [16, 87, 24, 9],\n",
              " [16, 87, 24, 9, 5],\n",
              " [16, 87, 24, 9, 5, 6],\n",
              " [16, 87, 24, 9, 5, 6, 54],\n",
              " [17, 164],\n",
              " [17, 164, 6],\n",
              " [17, 164, 6, 165],\n",
              " [17, 164, 6, 165, 166],\n",
              " [17, 164, 6, 165, 166, 43],\n",
              " [17, 164, 6, 165, 166, 43, 167],\n",
              " [17, 164, 6, 165, 166, 43, 167, 22],\n",
              " [17, 164, 6, 165, 166, 43, 167, 22, 168],\n",
              " [17, 164, 6, 165, 166, 43, 167, 22, 168, 169],\n",
              " [17, 164, 6, 165, 166, 43, 167, 22, 168, 169, 170],\n",
              " [17, 164, 6, 165, 166, 43, 167, 22, 168, 169, 170, 3],\n",
              " [17, 164, 6, 165, 166, 43, 167, 22, 168, 169, 170, 3, 171],\n",
              " [7, 5],\n",
              " [7, 5, 6],\n",
              " [7, 5, 6, 20],\n",
              " [7, 5, 6, 20, 172],\n",
              " [7, 5, 6, 20, 172, 173],\n",
              " [7, 5, 6, 20, 172, 173, 174],\n",
              " [7, 5, 6, 20, 172, 173, 174, 22],\n",
              " [7, 5, 6, 20, 172, 173, 174, 22, 175],\n",
              " [7, 5, 6, 20, 172, 173, 174, 22, 175, 88],\n",
              " [7, 5, 6, 20, 172, 173, 174, 22, 175, 88, 6],\n",
              " [7, 5, 6, 20, 172, 173, 174, 22, 175, 88, 6, 78],\n",
              " [176, 3],\n",
              " [176, 3, 89],\n",
              " [176, 3, 89, 70],\n",
              " [176, 3, 89, 70, 177],\n",
              " [176, 3, 89, 70, 177, 2],\n",
              " [176, 3, 89, 70, 177, 2, 27],\n",
              " [176, 3, 89, 70, 177, 2, 27, 22],\n",
              " [176, 3, 89, 70, 177, 2, 27, 22, 178],\n",
              " [176, 3, 89, 70, 177, 2, 27, 22, 178, 89],\n",
              " [176, 3, 89, 70, 177, 2, 27, 22, 178, 89, 71],\n",
              " [176, 3, 89, 70, 177, 2, 27, 22, 178, 89, 71, 2],\n",
              " [176, 3, 89, 70, 177, 2, 27, 22, 178, 89, 71, 2, 40],\n",
              " [32, 179],\n",
              " [32, 179, 12],\n",
              " [32, 179, 12, 180],\n",
              " [32, 179, 12, 180, 22],\n",
              " [32, 179, 12, 180, 22, 181],\n",
              " [32, 179, 12, 180, 22, 181, 2],\n",
              " [32, 179, 12, 180, 22, 181, 2, 8],\n",
              " [32, 179, 12, 180, 22, 181, 2, 8, 22],\n",
              " [32, 179, 12, 180, 22, 181, 2, 8, 22, 182],\n",
              " [32, 179, 12, 180, 22, 181, 2, 8, 22, 182, 3],\n",
              " [32, 179, 12, 180, 22, 181, 2, 8, 22, 182, 3, 59],\n",
              " [8, 183],\n",
              " [8, 183, 184],\n",
              " [16, 60],\n",
              " [16, 60, 185],\n",
              " [16, 60, 185, 5],\n",
              " [16, 60, 185, 5, 6],\n",
              " [16, 60, 185, 5, 6, 9],\n",
              " [16, 60, 185, 5, 6, 9, 186],\n",
              " [17, 1],\n",
              " [17, 1, 29],\n",
              " [17, 1, 29, 18],\n",
              " [17, 1, 29, 18, 4],\n",
              " [17, 1, 29, 18, 4, 90],\n",
              " [17, 1, 29, 18, 4, 90, 2],\n",
              " [17, 1, 29, 18, 4, 90, 2, 25],\n",
              " [17, 1, 29, 18, 4, 90, 2, 25, 31],\n",
              " [17, 1, 29, 18, 4, 90, 2, 25, 31, 187],\n",
              " [17, 1, 29, 18, 4, 90, 2, 25, 31, 187, 188],\n",
              " [17, 1, 29, 18, 4, 90, 2, 25, 31, 187, 188, 4],\n",
              " [17, 1, 29, 18, 4, 90, 2, 25, 31, 187, 188, 4, 9],\n",
              " [189, 81],\n",
              " [189, 81, 2],\n",
              " [189, 81, 2, 190],\n",
              " [189, 81, 2, 190, 191],\n",
              " [189, 81, 2, 190, 191, 192],\n",
              " [189, 81, 2, 190, 191, 192, 193],\n",
              " [189, 81, 2, 190, 191, 192, 193, 9],\n",
              " [189, 81, 2, 190, 191, 192, 193, 9, 1],\n",
              " [189, 81, 2, 190, 191, 192, 193, 9, 1, 194],\n",
              " [189, 81, 2, 190, 191, 192, 193, 9, 1, 194, 195],\n",
              " [189, 81, 2, 190, 191, 192, 193, 9, 1, 194, 195, 196],\n",
              " [189, 81, 2, 190, 191, 192, 193, 9, 1, 194, 195, 196, 14],\n",
              " [189, 81, 2, 190, 191, 192, 193, 9, 1, 194, 195, 196, 14, 91],\n",
              " [197, 4],\n",
              " [197, 4, 198],\n",
              " [197, 4, 198, 12],\n",
              " [197, 4, 198, 12, 199],\n",
              " [197, 4, 198, 12, 199, 92],\n",
              " [197, 4, 198, 12, 199, 92, 2],\n",
              " [197, 4, 198, 12, 199, 92, 2, 8],\n",
              " [93, 200],\n",
              " [93, 200, 51],\n",
              " [93, 200, 51, 201],\n",
              " [93, 200, 51, 201, 94],\n",
              " [93, 200, 51, 201, 94, 72],\n",
              " [93, 200, 51, 201, 94, 72, 202],\n",
              " [93, 200, 51, 201, 94, 72, 202, 203],\n",
              " [93, 200, 51, 201, 94, 72, 202, 203, 52],\n",
              " [93, 200, 51, 201, 94, 72, 202, 203, 52, 1],\n",
              " [93, 200, 51, 201, 94, 72, 202, 203, 52, 1, 75],\n",
              " [38, 1],\n",
              " [38, 1, 204],\n",
              " [38, 1, 204, 2],\n",
              " [38, 1, 204, 2, 18],\n",
              " [38, 1, 204, 2, 18, 31],\n",
              " [38, 1, 204, 2, 18, 31, 205],\n",
              " [38, 1, 204, 2, 18, 31, 205, 206],\n",
              " [38, 1, 204, 2, 18, 31, 205, 206, 12],\n",
              " [38, 1, 204, 2, 18, 31, 205, 206, 12, 207],\n",
              " [38, 1, 204, 2, 18, 31, 205, 206, 12, 207, 14],\n",
              " [38, 1, 204, 2, 18, 31, 205, 206, 12, 207, 14, 1],\n",
              " [208, 209],\n",
              " [208, 209, 5],\n",
              " [208, 209, 5, 6],\n",
              " [208, 209, 5, 6, 9],\n",
              " [208, 209, 5, 6, 9, 1],\n",
              " [208, 209, 5, 6, 9, 1, 210],\n",
              " [208, 209, 5, 6, 9, 1, 210, 2],\n",
              " [208, 209, 5, 6, 9, 1, 210, 2, 211],\n",
              " [208, 209, 5, 6, 9, 1, 210, 2, 211, 59],\n",
              " [208, 209, 5, 6, 9, 1, 210, 2, 211, 59, 4],\n",
              " [208, 209, 5, 6, 9, 1, 210, 2, 211, 59, 4, 8],\n",
              " [208, 209, 5, 6, 9, 1, 210, 2, 211, 59, 4, 8, 7],\n",
              " [212, 28],\n",
              " [212, 28, 1],\n",
              " [212, 28, 1, 213],\n",
              " [212, 28, 1, 213, 5],\n",
              " [212, 28, 1, 213, 5, 214],\n",
              " [212, 28, 1, 213, 5, 214, 215],\n",
              " [212, 28, 1, 213, 5, 214, 215, 4],\n",
              " [212, 28, 1, 213, 5, 214, 215, 4, 7],\n",
              " [212, 28, 1, 213, 5, 214, 215, 4, 7, 79],\n",
              " [212, 28, 1, 213, 5, 214, 215, 4, 7, 79, 80],\n",
              " [212, 28, 1, 213, 5, 214, 215, 4, 7, 79, 80, 90],\n",
              " [212, 28, 1, 213, 5, 214, 215, 4, 7, 79, 80, 90, 2],\n",
              " [212, 28, 1, 213, 5, 214, 215, 4, 7, 79, 80, 90, 2, 29],\n",
              " [216, 14],\n",
              " [216, 14, 53],\n",
              " [216, 14, 53, 1],\n",
              " [216, 14, 53, 1, 217],\n",
              " [216, 14, 53, 1, 217, 218],\n",
              " [216, 14, 53, 1, 217, 218, 219],\n",
              " [216, 14, 53, 1, 217, 218, 219, 4],\n",
              " [216, 14, 53, 1, 217, 218, 219, 4, 220],\n",
              " [216, 14, 53, 1, 217, 218, 219, 4, 220, 55],\n",
              " [221, 7],\n",
              " [221, 7, 61],\n",
              " [221, 7, 61, 222],\n",
              " [221, 7, 61, 222, 14],\n",
              " [221, 7, 61, 222, 14, 95],\n",
              " [16, 223],\n",
              " [16, 223, 24],\n",
              " [16, 223, 24, 224],\n",
              " [16, 223, 24, 224, 225],\n",
              " [16, 223, 24, 224, 225, 226],\n",
              " [16, 223, 24, 224, 225, 226, 7],\n",
              " [16, 223, 24, 224, 225, 226, 7, 227],\n",
              " [16, 223, 24, 224, 225, 226, 7, 227, 52],\n",
              " [16, 223, 24, 224, 225, 226, 7, 227, 52, 1],\n",
              " [16, 223, 24, 224, 225, 226, 7, 227, 52, 1, 5],\n",
              " [16, 223, 24, 224, 225, 226, 7, 227, 52, 1, 5, 6],\n",
              " [16, 223, 24, 224, 225, 226, 7, 227, 52, 1, 5, 6, 13],\n",
              " [16, 223, 24, 224, 225, 226, 7, 227, 52, 1, 5, 6, 13, 2],\n",
              " [44, 62],\n",
              " [44, 62, 34],\n",
              " [17, 10],\n",
              " [17, 10, 3],\n",
              " [17, 10, 3, 9],\n",
              " [17, 10, 3, 9, 3],\n",
              " [17, 10, 3, 9, 3, 228],\n",
              " [17, 10, 3, 9, 3, 228, 229],\n",
              " [17, 10, 3, 9, 3, 228, 229, 1],\n",
              " [17, 10, 3, 9, 3, 228, 229, 1, 230],\n",
              " [17, 10, 3, 9, 3, 228, 229, 1, 230, 231],\n",
              " [17, 10, 3, 9, 3, 228, 229, 1, 230, 231, 96],\n",
              " [17, 10, 3, 9, 3, 228, 229, 1, 230, 231, 96, 97],\n",
              " [17, 10, 3, 9, 3, 228, 229, 1, 230, 231, 96, 97, 98],\n",
              " [17, 10, 3, 9, 3, 228, 229, 1, 230, 231, 96, 97, 98, 2],\n",
              " [17, 10, 3, 9, 3, 228, 229, 1, 230, 231, 96, 97, 98, 2, 5],\n",
              " [17, 10, 3, 9, 3, 228, 229, 1, 230, 231, 96, 97, 98, 2, 5, 6],\n",
              " [11, 4],\n",
              " [11, 4, 232],\n",
              " [11, 4, 232, 233],\n",
              " [11, 4, 232, 233, 234],\n",
              " [11, 4, 232, 233, 234, 3],\n",
              " [11, 4, 232, 233, 234, 3, 235],\n",
              " [11, 4, 232, 233, 234, 3, 235, 2],\n",
              " [11, 4, 232, 233, 234, 3, 235, 2, 63],\n",
              " [11, 4, 232, 233, 234, 3, 235, 2, 63, 4],\n",
              " [11, 4, 232, 233, 234, 3, 235, 2, 63, 4, 27],\n",
              " [11, 4, 232, 233, 234, 3, 235, 2, 63, 4, 27, 19],\n",
              " [37, 56],\n",
              " [37, 56, 236],\n",
              " [37, 56, 236, 14],\n",
              " [37, 56, 236, 14, 10],\n",
              " [37, 56, 236, 14, 10, 3],\n",
              " [37, 56, 236, 14, 10, 3, 237],\n",
              " [37, 56, 236, 14, 10, 3, 237, 238],\n",
              " [37, 56, 236, 14, 10, 3, 237, 238, 28],\n",
              " [37, 56, 236, 14, 10, 3, 237, 238, 28, 1],\n",
              " [37, 56, 236, 14, 10, 3, 237, 238, 28, 1, 239],\n",
              " [37, 56, 236, 14, 10, 3, 237, 238, 28, 1, 239, 4],\n",
              " [30, 63],\n",
              " [30, 63, 37],\n",
              " [30, 63, 37, 56],\n",
              " [30, 63, 37, 56, 99],\n",
              " [30, 63, 37, 56, 99, 100],\n",
              " [30, 63, 37, 56, 99, 100, 38],\n",
              " [30, 63, 37, 56, 99, 100, 38, 7],\n",
              " [30, 63, 37, 56, 99, 100, 38, 7, 38],\n",
              " [30, 63, 37, 56, 99, 100, 38, 7, 38, 4],\n",
              " [30, 63, 37, 56, 99, 100, 38, 7, 38, 4, 96],\n",
              " [30, 63, 37, 56, 99, 100, 38, 7, 38, 4, 96, 240],\n",
              " [30, 63, 37, 56, 99, 100, 38, 7, 38, 4, 96, 240, 1],\n",
              " [30, 63, 37, 56, 99, 100, 38, 7, 38, 4, 96, 240, 1, 241],\n",
              " [242, 100],\n",
              " [242, 100, 1],\n",
              " [242, 100, 1, 95],\n",
              " [242, 100, 1, 95, 243],\n",
              " [242, 100, 1, 95, 243, 13],\n",
              " [242, 100, 1, 95, 243, 13, 244],\n",
              " [242, 100, 1, 95, 243, 13, 244, 245],\n",
              " [242, 100, 1, 95, 243, 13, 244, 245, 246],\n",
              " [242, 100, 1, 95, 243, 13, 244, 245, 246, 10],\n",
              " [242, 100, 1, 95, 243, 13, 244, 245, 246, 10, 3],\n",
              " [101, 1],\n",
              " [101, 1, 247],\n",
              " [101, 1, 247, 2],\n",
              " [101, 1, 247, 2, 248],\n",
              " [101, 1, 247, 2, 248, 99],\n",
              " [101, 1, 247, 2, 248, 99, 249],\n",
              " [101, 1, 247, 2, 248, 99, 249, 250],\n",
              " [101, 1, 247, 2, 248, 99, 249, 250, 3],\n",
              " [101, 1, 247, 2, 248, 99, 249, 250, 3, 251],\n",
              " [101, 1, 247, 2, 248, 99, 249, 250, 3, 251, 34],\n",
              " [101, 1, 247, 2, 248, 99, 249, 250, 3, 251, 34, 252],\n",
              " [253, 2],\n",
              " [253, 2, 1],\n",
              " [253, 2, 1, 13],\n",
              " [16, 254],\n",
              " [16, 254, 24],\n",
              " [16, 254, 24, 41],\n",
              " [16, 254, 24, 41, 1],\n",
              " [16, 254, 24, 41, 1, 35],\n",
              " [16, 254, 24, 41, 1, 35, 2],\n",
              " [16, 254, 24, 41, 1, 35, 2, 10],\n",
              " [16, 254, 24, 41, 1, 35, 2, 10, 3],\n",
              " [16, 254, 24, 41, 1, 35, 2, 10, 3, 3],\n",
              " [16, 254, 24, 41, 1, 35, 2, 10, 3, 3, 1],\n",
              " [16, 254, 24, 41, 1, 35, 2, 10, 3, 3, 1, 64],\n",
              " [16, 254, 24, 41, 1, 35, 2, 10, 3, 3, 1, 64, 2],\n",
              " [16, 254, 24, 41, 1, 35, 2, 10, 3, 3, 1, 64, 2, 5],\n",
              " [16, 254, 24, 41, 1, 35, 2, 10, 3, 3, 1, 64, 2, 5, 6],\n",
              " [17, 10],\n",
              " [17, 10, 3],\n",
              " [17, 10, 3, 255],\n",
              " [17, 10, 3, 255, 1],\n",
              " [17, 10, 3, 255, 1, 256],\n",
              " [17, 10, 3, 255, 1, 256, 35],\n",
              " [17, 10, 3, 255, 1, 256, 35, 3],\n",
              " [17, 10, 3, 255, 1, 256, 35, 3, 1],\n",
              " [17, 10, 3, 255, 1, 256, 35, 3, 1, 64],\n",
              " [17, 10, 3, 255, 1, 256, 35, 3, 1, 64, 2],\n",
              " [17, 10, 3, 255, 1, 256, 35, 3, 1, 64, 2, 5],\n",
              " [17, 10, 3, 255, 1, 256, 35, 3, 1, 64, 2, 5, 6],\n",
              " [17, 10, 3, 255, 1, 256, 35, 3, 1, 64, 2, 5, 6, 15],\n",
              " [102, 3],\n",
              " [102, 3, 257],\n",
              " [102, 3, 257, 57],\n",
              " [102, 3, 257, 57, 60],\n",
              " [102, 3, 257, 57, 60, 2],\n",
              " [102, 3, 257, 57, 60, 2, 57],\n",
              " [102, 3, 257, 57, 60, 2, 57, 86],\n",
              " [102, 3, 257, 57, 60, 2, 57, 86, 2],\n",
              " [102, 3, 257, 57, 60, 2, 57, 86, 2, 1],\n",
              " [102, 3, 257, 57, 60, 2, 57, 86, 2, 1, 8],\n",
              " [102, 3, 257, 57, 60, 2, 57, 86, 2, 1, 8, 18],\n",
              " [102, 3, 257, 57, 60, 2, 57, 86, 2, 1, 8, 18, 42],\n",
              " [102, 3, 257, 57, 60, 2, 57, 86, 2, 1, 8, 18, 42, 58],\n",
              " [258, 259],\n",
              " [258, 259, 20],\n",
              " [258, 259, 20, 10],\n",
              " [258, 259, 20, 10, 3],\n",
              " [258, 259, 20, 10, 3, 45],\n",
              " [258, 259, 20, 10, 3, 45, 260],\n",
              " [258, 259, 20, 10, 3, 45, 260, 15],\n",
              " [258, 259, 20, 10, 3, 45, 260, 15, 1],\n",
              " [258, 259, 20, 10, 3, 45, 260, 15, 1, 82],\n",
              " [258, 259, 20, 10, 3, 45, 260, 15, 1, 82, 83],\n",
              " [258, 259, 20, 10, 3, 45, 260, 15, 1, 82, 83, 12],\n",
              " [258, 259, 20, 10, 3, 45, 260, 15, 1, 82, 83, 12, 103],\n",
              " [258, 259, 20, 10, 3, 45, 260, 15, 1, 82, 83, 12, 103, 1],\n",
              " [261, 35],\n",
              " [261, 35, 3],\n",
              " [261, 35, 3, 1],\n",
              " [261, 35, 3, 1, 64],\n",
              " [261, 35, 3, 1, 64, 2],\n",
              " [261, 35, 3, 1, 64, 2, 5],\n",
              " [261, 35, 3, 1, 64, 2, 5, 6],\n",
              " [40, 262],\n",
              " [40, 262, 98],\n",
              " [40, 262, 98, 4],\n",
              " [40, 262, 98, 4, 92],\n",
              " [40, 262, 98, 4, 92, 2],\n",
              " [40, 262, 98, 4, 92, 2, 8],\n",
              " [40, 262, 98, 4, 92, 2, 8, 97],\n",
              " [40, 262, 98, 4, 92, 2, 8, 97, 5],\n",
              " [40, 262, 98, 4, 92, 2, 8, 97, 5, 11],\n",
              " [263, 264],\n",
              " [263, 264, 4],\n",
              " [263, 264, 4, 265],\n",
              " [263, 264, 4, 265, 2],\n",
              " [263, 264, 4, 265, 2, 5],\n",
              " [263, 264, 4, 265, 2, 5, 6],\n",
              " [263, 264, 4, 265, 2, 5, 6, 11],\n",
              " [266, 33],\n",
              " [266, 33, 55],\n",
              " [266, 33, 55, 12],\n",
              " [266, 33, 55, 12, 267],\n",
              " [266, 33, 55, 12, 267, 5],\n",
              " [266, 33, 55, 12, 267, 5, 6],\n",
              " [266, 33, 55, 12, 267, 5, 6, 11],\n",
              " [268, 269],\n",
              " [268, 269, 2],\n",
              " [268, 269, 2, 5],\n",
              " [268, 269, 2, 5, 54],\n",
              " [268, 269, 2, 5, 54, 21],\n",
              " [268, 269, 2, 5, 54, 21, 94],\n",
              " [93, 270],\n",
              " [93, 270, 65],\n",
              " [93, 270, 65, 271],\n",
              " [93, 270, 65, 271, 272],\n",
              " [93, 270, 65, 271, 272, 273],\n",
              " [93, 270, 65, 271, 272, 273, 4],\n",
              " [93, 270, 65, 271, 272, 273, 4, 274],\n",
              " [93, 270, 65, 271, 272, 273, 4, 274, 104],\n",
              " [93, 270, 65, 271, 272, 273, 4, 274, 104, 7],\n",
              " [8, 6],\n",
              " [8, 6, 275],\n",
              " [8, 6, 275, 105],\n",
              " [8, 6, 275, 105, 84],\n",
              " [8, 6, 275, 105, 84, 21],\n",
              " [8, 6, 275, 105, 84, 21, 4],\n",
              " [8, 6, 275, 105, 84, 21, 4, 276],\n",
              " [8, 6, 275, 105, 84, 21, 4, 276, 2],\n",
              " [5, 11],\n",
              " [277, 278],\n",
              " [277, 278, 50],\n",
              " [277, 278, 50, 35],\n",
              " [277, 278, 50, 35, 104],\n",
              " [277, 278, 50, 35, 104, 7],\n",
              " [277, 278, 50, 35, 104, 7, 5],\n",
              " [277, 278, 50, 35, 104, 7, 5, 6],\n",
              " [277, 278, 50, 35, 104, 7, 5, 6, 15],\n",
              " [277, 278, 50, 35, 104, 7, 5, 6, 15, 279],\n",
              " [277, 278, 50, 35, 104, 7, 5, 6, 15, 279, 61],\n",
              " [277, 278, 50, 35, 104, 7, 5, 6, 15, 279, 61, 280],\n",
              " [16, 281],\n",
              " [16, 281, 282],\n",
              " [16, 281, 282, 106],\n",
              " [16, 281, 282, 106, 36],\n",
              " [16, 281, 282, 106, 36, 5],\n",
              " [16, 281, 282, 106, 36, 5, 6],\n",
              " [16, 281, 282, 106, 36, 5, 6, 13],\n",
              " [16, 281, 282, 106, 36, 5, 6, 13, 2],\n",
              " [16, 281, 282, 106, 36, 5, 6, 13, 2, 44],\n",
              " [16, 281, 282, 106, 36, 5, 6, 13, 2, 44, 62],\n",
              " [16, 281, 282, 106, 36, 5, 6, 13, 2, 44, 62, 34],\n",
              " [16, 281, 282, 106, 36, 5, 6, 13, 2, 44, 62, 34, 283],\n",
              " [16, 281, 282, 106, 36, 5, 6, 13, 2, 44, 62, 34, 283, 7],\n",
              " [17, 27],\n",
              " [17, 27, 19],\n",
              " [17, 27, 19, 46],\n",
              " [17, 27, 19, 46, 59],\n",
              " [17, 27, 19, 46, 59, 284],\n",
              " [17, 27, 19, 46, 59, 284, 285],\n",
              " [17, 27, 19, 46, 59, 284, 285, 107],\n",
              " [17, 27, 19, 46, 59, 284, 285, 107, 66],\n",
              " [17, 27, 19, 46, 59, 284, 285, 107, 66, 286],\n",
              " [287, 288],\n",
              " [287, 288, 19],\n",
              " [287, 288, 19, 289],\n",
              " [287, 288, 19, 289, 27],\n",
              " [287, 288, 19, 289, 27, 19],\n",
              " [287, 288, 19, 289, 27, 19, 290],\n",
              " [287, 288, 19, 289, 27, 19, 290, 27],\n",
              " [287, 288, 19, 289, 27, 19, 290, 27, 19],\n",
              " [287, 288, 19, 289, 27, 19, 290, 27, 19, 66],\n",
              " [287, 288, 19, 289, 27, 19, 290, 27, 19, 66, 108],\n",
              " [27, 19],\n",
              " [27, 19, 66],\n",
              " [27, 19, 66, 108],\n",
              " [27, 19, 66, 108, 291],\n",
              " [27, 19, 66, 108, 291, 19],\n",
              " [27, 19, 66, 108, 291, 19, 292],\n",
              " [27, 19, 66, 108, 291, 19, 292, 293],\n",
              " [27, 19, 66, 108, 291, 19, 292, 293, 19],\n",
              " [27, 19, 66, 108, 291, 19, 292, 293, 19, 4],\n",
              " [30, 63],\n",
              " [30, 63, 45],\n",
              " [30, 63, 45, 294],\n",
              " [30, 63, 45, 294, 36],\n",
              " [30, 63, 45, 294, 36, 5],\n",
              " [30, 63, 45, 294, 36, 5, 6],\n",
              " [30, 63, 45, 294, 36, 5, 6, 13],\n",
              " [30, 63, 45, 294, 36, 5, 6, 13, 2],\n",
              " [30, 63, 45, 294, 36, 5, 6, 13, 2, 44],\n",
              " [30, 63, 45, 294, 36, 5, 6, 13, 2, 44, 60],\n",
              " [30, 63, 45, 294, 36, 5, 6, 13, 2, 44, 60, 34],\n",
              " [30, 63, 45, 294, 36, 5, 6, 13, 2, 44, 60, 34, 15],\n",
              " [88, 7],\n",
              " [88, 7, 295],\n",
              " [88, 7, 295, 296],\n",
              " [88, 7, 295, 296, 91],\n",
              " [88, 7, 295, 296, 91, 41],\n",
              " [88, 7, 295, 296, 91, 41, 297],\n",
              " [88, 7, 295, 296, 91, 41, 297, 298],\n",
              " [88, 7, 295, 296, 91, 41, 297, 298, 14],\n",
              " [88, 7, 295, 296, 91, 41, 297, 298, 14, 36],\n",
              " [88, 7, 295, 296, 91, 41, 297, 298, 14, 36, 13],\n",
              " [16, 299],\n",
              " [16, 299, 1],\n",
              " [16, 299, 1, 8],\n",
              " [16, 299, 1, 8, 18],\n",
              " [16, 299, 1, 8, 18, 47],\n",
              " [16, 299, 1, 8, 18, 47, 65],\n",
              " [16, 299, 1, 8, 18, 47, 65, 4],\n",
              " [16, 299, 1, 8, 18, 47, 65, 4, 29],\n",
              " [16, 299, 1, 8, 18, 47, 65, 4, 29, 109],\n",
              " [110, 111],\n",
              " [110, 111, 23],\n",
              " [110, 111, 23, 112],\n",
              " [110, 111, 23, 112, 300],\n",
              " [110, 111, 23, 112, 300, 20],\n",
              " [110, 111, 23, 112, 300, 20, 113],\n",
              " [110, 111, 23, 112, 300, 20, 113, 47],\n",
              " [110, 111, 23, 112, 300, 20, 113, 47, 45],\n",
              " [110, 111, 23, 112, 300, 20, 113, 47, 45, 48],\n",
              " [110, 111, 23, 112, 300, 20, 113, 47, 45, 48, 5],\n",
              " [110, 111, 23, 112, 300, 20, 113, 47, 45, 48, 5, 6],\n",
              " [11, 4],\n",
              " [11, 4, 114],\n",
              " [11, 4, 114, 67],\n",
              " [11, 4, 114, 67, 5],\n",
              " [11, 4, 114, 67, 5, 6],\n",
              " [11, 4, 114, 67, 5, 6, 11],\n",
              " [11, 4, 114, 67, 5, 6, 11, 68],\n",
              " [11, 4, 114, 67, 5, 6, 11, 68, 8],\n",
              " [11, 4, 114, 67, 5, 6, 11, 68, 8, 28],\n",
              " [11, 4, 114, 67, 5, 6, 11, 68, 8, 28, 1],\n",
              " [11, 4, 114, 67, 5, 6, 11, 68, 8, 28, 1, 39],\n",
              " [32, 33],\n",
              " [32, 33, 21],\n",
              " [32, 33, 21, 301],\n",
              " [32, 33, 21, 301, 106],\n",
              " [32, 33, 21, 301, 106, 46],\n",
              " [32, 33, 21, 301, 106, 46, 37],\n",
              " [32, 33, 21, 301, 106, 46, 37, 7],\n",
              " [32, 33, 21, 301, 106, 46, 37, 7, 115],\n",
              " [48, 43],\n",
              " [48, 43, 4],\n",
              " [48, 43, 4, 302],\n",
              " [48, 43, 4, 302, 5],\n",
              " [48, 43, 4, 302, 5, 6],\n",
              " [48, 43, 4, 302, 5, 6, 11],\n",
              " [48, 43, 4, 302, 5, 6, 11, 22],\n",
              " [48, 43, 4, 302, 5, 6, 11, 22, 303],\n",
              " [48, 43, 4, 302, 5, 6, 11, 22, 303, 304],\n",
              " [48, 43, 4, 302, 5, 6, 11, 22, 303, 304, 102],\n",
              " [48, 43, 4, 302, 5, 6, 11, 22, 303, 304, 102, 3],\n",
              " [48, 43, 4, 302, 5, 6, 11, 22, 303, 304, 102, 3, 1],\n",
              " [48, 43, 4, 302, 5, 6, 11, 22, 303, 304, 102, 3, 1, 116],\n",
              " [7, 1],\n",
              " [7, 1, 23],\n",
              " [17, 26],\n",
              " [17, 26, 9],\n",
              " [17, 26, 9, 305],\n",
              " [17, 26, 9, 305, 20],\n",
              " [17, 26, 9, 305, 20, 1],\n",
              " [17, 26, 9, 305, 20, 1, 46],\n",
              " [17, 26, 9, 305, 20, 1, 46, 15],\n",
              " [17, 26, 9, 305, 20, 1, 46, 15, 306],\n",
              " [17, 26, 9, 305, 20, 1, 46, 15, 306, 101],\n",
              " [17, 26, 9, 305, 20, 1, 46, 15, 306, 101, 1],\n",
              " [17, 26, 9, 305, 20, 1, 46, 15, 306, 101, 1, 8],\n",
              " [17, 26, 9, 305, 20, 1, 46, 15, 306, 101, 1, 8, 18],\n",
              " [42, 4],\n",
              " [42, 4, 23],\n",
              " [42, 4, 23, 307],\n",
              " [42, 4, 23, 307, 308],\n",
              " [42, 4, 23, 307, 308, 7],\n",
              " [42, 4, 23, 307, 308, 7, 48],\n",
              " [42, 4, 23, 307, 308, 7, 48, 5],\n",
              " [42, 4, 23, 307, 308, 7, 48, 5, 6],\n",
              " [42, 4, 23, 307, 308, 7, 48, 5, 6, 11],\n",
              " [42, 4, 23, 307, 308, 7, 48, 5, 6, 11, 4],\n",
              " [42, 4, 23, 307, 308, 7, 48, 5, 6, 11, 4, 67],\n",
              " [42, 4, 23, 307, 308, 7, 48, 5, 6, 11, 4, 67, 43],\n",
              " [42, 4, 23, 307, 308, 7, 48, 5, 6, 11, 4, 67, 43, 68],\n",
              " [8, 309],\n",
              " [8, 309, 28],\n",
              " [8, 309, 28, 10],\n",
              " [8, 309, 28, 10, 3],\n",
              " [8, 309, 28, 10, 3, 1],\n",
              " [8, 309, 28, 10, 3, 1, 117],\n",
              " [8, 309, 28, 10, 3, 1, 117, 87],\n",
              " [8, 309, 28, 10, 3, 1, 117, 87, 49],\n",
              " [8, 309, 28, 10, 3, 1, 117, 87, 49, 310],\n",
              " [8, 309, 28, 10, 3, 1, 117, 87, 49, 310, 2],\n",
              " [8, 309, 28, 10, 3, 1, 117, 87, 49, 310, 2, 1],\n",
              " [8, 309, 28, 10, 3, 1, 117, 87, 49, 310, 2, 1, 8],\n",
              " [8, 309, 28, 10, 3, 1, 117, 87, 49, 310, 2, 1, 8, 18],\n",
              " [47, 65],\n",
              " [47, 65, 4],\n",
              " [47, 65, 4, 29],\n",
              " [47, 65, 4, 29, 109],\n",
              " [47, 65, 4, 29, 109, 110],\n",
              " [47, 65, 4, 29, 109, 110, 111],\n",
              " [47, 65, 4, 29, 109, 110, 111, 23],\n",
              " [47, 65, 4, 29, 109, 110, 111, 23, 112],\n",
              " [47, 65, 4, 29, 109, 110, 111, 23, 112, 311],\n",
              " [47, 65, 4, 29, 109, 110, 111, 23, 112, 311, 20],\n",
              " [113, 47],\n",
              " [113, 47, 45],\n",
              " [113, 47, 45, 48],\n",
              " [113, 47, 45, 48, 5],\n",
              " [113, 47, 45, 48, 5, 6],\n",
              " [113, 47, 45, 48, 5, 6, 11],\n",
              " [113, 47, 45, 48, 5, 6, 11, 4],\n",
              " [113, 47, 45, 48, 5, 6, 11, 4, 67],\n",
              " [113, 47, 45, 48, 5, 6, 11, 4, 67, 68],\n",
              " [113, 47, 45, 48, 5, 6, 11, 4, 67, 68, 8],\n",
              " [28, 1],\n",
              " [28, 1, 39],\n",
              " [28, 1, 39, 32],\n",
              " [28, 1, 39, 32, 33],\n",
              " [28, 1, 39, 32, 33, 21],\n",
              " [28, 1, 39, 32, 33, 21, 118],\n",
              " [28, 1, 39, 32, 33, 21, 118, 3],\n",
              " [28, 1, 39, 32, 33, 21, 118, 3, 312],\n",
              " [28, 1, 39, 32, 33, 21, 118, 3, 312, 28],\n",
              " [28, 1, 39, 32, 33, 21, 118, 3, 312, 28, 1],\n",
              " [28, 1, 39, 32, 33, 21, 118, 3, 312, 28, 1, 313],\n",
              " [4, 105],\n",
              " [4, 105, 15],\n",
              " [4, 105, 15, 314],\n",
              " [4, 105, 15, 314, 3],\n",
              " [4, 105, 15, 314, 3, 1],\n",
              " [4, 105, 15, 314, 3, 1, 8],\n",
              " [4, 105, 15, 314, 3, 1, 8, 18],\n",
              " [4, 105, 15, 314, 3, 1, 8, 18, 1],\n",
              " [4, 105, 15, 314, 3, 1, 8, 18, 1, 39],\n",
              " [4, 105, 15, 314, 3, 1, 8, 18, 1, 39, 32],\n",
              " [33, 21],\n",
              " [33, 21, 118],\n",
              " [33, 21, 118, 4],\n",
              " [33, 21, 118, 4, 315],\n",
              " [33, 21, 118, 4, 315, 2],\n",
              " [33, 21, 118, 4, 315, 2, 103],\n",
              " [33, 21, 118, 4, 315, 2, 103, 35],\n",
              " [33, 21, 118, 4, 315, 2, 103, 35, 4],\n",
              " [33, 21, 118, 4, 315, 2, 103, 35, 4, 316],\n",
              " [33, 21, 118, 4, 315, 2, 103, 35, 4, 316, 23],\n",
              " [317, 3],\n",
              " [317, 3, 318],\n",
              " [317, 3, 318, 319],\n",
              " [317, 3, 318, 319, 26],\n",
              " [317, 3, 318, 319, 26, 9],\n",
              " [317, 3, 318, 319, 26, 9, 320],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20, 3],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20, 3, 85],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20, 3, 85, 2],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20, 3, 85, 2, 117],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20, 3, 85, 2, 117, 322],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20, 3, 85, 2, 117, 322, 2],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20, 3, 85, 2, 117, 322, 2, 1],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20, 3, 85, 2, 117, 322, 2, 1, 10],\n",
              " [317, 3, 318, 319, 26, 9, 320, 7, 321, 20, 3, 85, 2, 117, 322, 2, 1, 10, 3],\n",
              " [23, 323],\n",
              " [23, 323, 1],\n",
              " [23, 323, 1, 324],\n",
              " [23, 323, 1, 324, 2],\n",
              " [23, 323, 1, 324, 2, 5],\n",
              " [23, 323, 1, 324, 2, 5, 6],\n",
              " [23, 323, 1, 324, 2, 5, 6, 11],\n",
              " [23, 323, 1, 324, 2, 5, 6, 11, 15],\n",
              " [23, 323, 1, 324, 2, 5, 6, 11, 15, 325],\n",
              " [23, 323, 1, 324, 2, 5, 6, 11, 15, 325, 3],\n",
              " [23, 323, 1, 324, 2, 5, 6, 11, 15, 325, 3, 1],\n",
              " [23, 323, 1, 324, 2, 5, 6, 11, 15, 325, 3, 1, 116],\n",
              " [23, 323, 1, 324, 2, 5, 6, 11, 15, 325, 3, 1, 116, 2],\n",
              " [23, 323, 1, 324, 2, 5, 6, 11, 15, 325, 3, 1, 116, 2, 1],\n",
              " [23, 4],\n",
              " [23, 4, 114],\n",
              " [23, 4, 114, 326],\n",
              " [23, 4, 114, 326, 327],\n",
              " [23, 4, 114, 326, 327, 3],\n",
              " [23, 4, 114, 326, 327, 3, 1],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5, 6],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5, 6, 13],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5, 6, 13, 2],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5, 6, 13, 2, 44],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5, 6, 13, 2, 44, 62],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5, 6, 13, 2, 44, 62, 34],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5, 6, 13, 2, 44, 62, 34, 41],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5, 6, 13, 2, 44, 62, 34, 41, 7],\n",
              " [23, 4, 114, 326, 327, 3, 1, 5, 6, 13, 2, 44, 62, 34, 41, 7, 61],\n",
              " [115, 328],\n",
              " [115, 328, 7],\n",
              " [115, 328, 7, 10],\n",
              " [115, 328, 7, 10, 3],\n",
              " [115, 328, 7, 10, 3, 14],\n",
              " [115, 328, 7, 10, 3, 14, 43],\n",
              " [115, 328, 7, 10, 3, 14, 43, 329],\n",
              " [115, 328, 7, 10, 3, 14, 43, 329, 22],\n",
              " [115, 328, 7, 10, 3, 14, 43, 329, 22, 107],\n",
              " [115, 328, 7, 10, 3, 14, 43, 329, 22, 107, 330],\n",
              " [115, 328, 7, 10, 3, 14, 43, 329, 22, 107, 330, 73],\n",
              " [46, 331],\n",
              " [46, 331, 14],\n",
              " [46, 331, 14, 5],\n",
              " [46, 331, 14, 5, 6],\n",
              " [46, 331, 14, 5, 6, 11],\n",
              " [46, 331, 14, 5, 6, 11, 15],\n",
              " [46, 331, 14, 5, 6, 11, 15, 332],\n",
              " [46, 331, 14, 5, 6, 11, 15, 332, 15],\n",
              " [46, 331, 14, 5, 6, 11, 15, 332, 15, 333],\n",
              " [46, 331, 14, 5, 6, 11, 15, 332, 15, 333, 7],\n",
              " [46, 331, 14, 5, 6, 11, 15, 332, 15, 333, 7, 334],\n",
              " [46, 331, 14, 5, 6, 11, 15, 332, 15, 333, 7, 334, 335],\n",
              " [46, 331, 14, 5, 6, 11, 15, 332, 15, 333, 7, 334, 335, 12]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# which is the longest sentence ? (needed for padding)\n",
        "\n",
        "max_len = max([len(x) for x in input_sequences])  # 19"
      ],
      "metadata": {
        "id": "fsPnqG3TQ-9S"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "tRsQx2ECRks5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(padded_input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePyUo1eFR8Fa",
        "outputId": "9d6bded3-d326-4190-dcee-e074f29f3314"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ...   0  16  49]\n",
            " [  0   0   0 ...  16  49  24]\n",
            " [  0   0   0 ...  49  24   9]\n",
            " ...\n",
            " [  0   0   0 ... 333   7 334]\n",
            " [  0   0   0 ...   7 334 335]\n",
            " [  0   0   0 ... 334 335  12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all except the last character\n",
        "\n",
        "x = padded_input_sequences[:, :-1]"
      ],
      "metadata": {
        "id": "R8jN0ez9SQnj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the last characters\n",
        "\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "8tBemqx0ShBj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wzH9GevMS2B0",
        "outputId": "982928d8-f4d6-404b-ac7a-7d2cbcdd8bdd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 49,  24,   9,   1, 119,  12,  36,   5,   6,  13,   1,  25,   3,\n",
              "       120,   9, 121, 122,   4,  69,   1, 123, 124, 125,  69, 126, 127,\n",
              "       129,  37,  70,   7,   1,  25,   4,  71,  26,  12, 130,  72, 131,\n",
              "         4,  50, 133,   4,  51,  73,  29,  30,  51,   1,  31,  74, 134,\n",
              "         3, 135,   4,  52,   1,  75,  38,  26,  31,  74, 136,   3, 137,\n",
              "       139,   4,  50, 140,   7,  76,  77,  26,   9,   1,  30,   2, 141,\n",
              "        78,   7,  79,  20,  39,  25,  53, 143,  40,  80, 144,  25,   5,\n",
              "        13,  41,  40,  81,   2,   1, 145, 146,   2, 147,  76,  77,   4,\n",
              "        12,  53, 149,  24,   9,  10,   3,   4,  24,   9,   1, 150,   2,\n",
              "        10,   3, 151,  32,  33,  21, 152,  10,   3,   9,   1,  82,  83,\n",
              "         5,   6,  54,  21,   4, 153,  55,  12,  84,   2,   5,   3,   1,\n",
              "       154,  10,   3,  31,  56, 155,  14, 156,  30, 157, 159, 160, 161,\n",
              "       162,   3,  85,   2,   1, 163,   2,  57,  86,  49,   2,   1,  18,\n",
              "        42,  58,  26,  42,  58,  87,  24,   9,   5,   6,  54, 164,   6,\n",
              "       165, 166,  43, 167,  22, 168, 169, 170,   3, 171,   5,   6,  20,\n",
              "       172, 173, 174,  22, 175,  88,   6,  78,   3,  89,  70, 177,   2,\n",
              "        27,  22, 178,  89,  71,   2,  40, 179,  12, 180,  22, 181,   2,\n",
              "         8,  22, 182,   3,  59, 183, 184,  60, 185,   5,   6,   9, 186,\n",
              "         1,  29,  18,   4,  90,   2,  25,  31, 187, 188,   4,   9,  81,\n",
              "         2, 190, 191, 192, 193,   9,   1, 194, 195, 196,  14,  91,   4,\n",
              "       198,  12, 199,  92,   2,   8, 200,  51, 201,  94,  72, 202, 203,\n",
              "        52,   1,  75,   1, 204,   2,  18,  31, 205, 206,  12, 207,  14,\n",
              "         1, 209,   5,   6,   9,   1, 210,   2, 211,  59,   4,   8,   7,\n",
              "        28,   1, 213,   5, 214, 215,   4,   7,  79,  80,  90,   2,  29,\n",
              "        14,  53,   1, 217, 218, 219,   4, 220,  55,   7,  61, 222,  14,\n",
              "        95, 223,  24, 224, 225, 226,   7, 227,  52,   1,   5,   6,  13,\n",
              "         2,  62,  34,  10,   3,   9,   3, 228, 229,   1, 230, 231,  96,\n",
              "        97,  98,   2,   5,   6,   4, 232, 233, 234,   3, 235,   2,  63,\n",
              "         4,  27,  19,  56, 236,  14,  10,   3, 237, 238,  28,   1, 239,\n",
              "         4,  63,  37,  56,  99, 100,  38,   7,  38,   4,  96, 240,   1,\n",
              "       241, 100,   1,  95, 243,  13, 244, 245, 246,  10,   3,   1, 247,\n",
              "         2, 248,  99, 249, 250,   3, 251,  34, 252,   2,   1,  13, 254,\n",
              "        24,  41,   1,  35,   2,  10,   3,   3,   1,  64,   2,   5,   6,\n",
              "        10,   3, 255,   1, 256,  35,   3,   1,  64,   2,   5,   6,  15,\n",
              "         3, 257,  57,  60,   2,  57,  86,   2,   1,   8,  18,  42,  58,\n",
              "       259,  20,  10,   3,  45, 260,  15,   1,  82,  83,  12, 103,   1,\n",
              "        35,   3,   1,  64,   2,   5,   6, 262,  98,   4,  92,   2,   8,\n",
              "        97,   5,  11, 264,   4, 265,   2,   5,   6,  11,  33,  55,  12,\n",
              "       267,   5,   6,  11, 269,   2,   5,  54,  21,  94, 270,  65, 271,\n",
              "       272, 273,   4, 274, 104,   7,   6, 275, 105,  84,  21,   4, 276,\n",
              "         2,  11, 278,  50,  35, 104,   7,   5,   6,  15, 279,  61, 280,\n",
              "       281, 282, 106,  36,   5,   6,  13,   2,  44,  62,  34, 283,   7,\n",
              "        27,  19,  46,  59, 284, 285, 107,  66, 286, 288,  19, 289,  27,\n",
              "        19, 290,  27,  19,  66, 108,  19,  66, 108, 291,  19, 292, 293,\n",
              "        19,   4,  63,  45, 294,  36,   5,   6,  13,   2,  44,  60,  34,\n",
              "        15,   7, 295, 296,  91,  41, 297, 298,  14,  36,  13, 299,   1,\n",
              "         8,  18,  47,  65,   4,  29, 109, 111,  23, 112, 300,  20, 113,\n",
              "        47,  45,  48,   5,   6,   4, 114,  67,   5,   6,  11,  68,   8,\n",
              "        28,   1,  39,  33,  21, 301, 106,  46,  37,   7, 115,  43,   4,\n",
              "       302,   5,   6,  11,  22, 303, 304, 102,   3,   1, 116,   1,  23,\n",
              "        26,   9, 305,  20,   1,  46,  15, 306, 101,   1,   8,  18,   4,\n",
              "        23, 307, 308,   7,  48,   5,   6,  11,   4,  67,  43,  68, 309,\n",
              "        28,  10,   3,   1, 117,  87,  49, 310,   2,   1,   8,  18,  65,\n",
              "         4,  29, 109, 110, 111,  23, 112, 311,  20,  47,  45,  48,   5,\n",
              "         6,  11,   4,  67,  68,   8,   1,  39,  32,  33,  21, 118,   3,\n",
              "       312,  28,   1, 313, 105,  15, 314,   3,   1,   8,  18,   1,  39,\n",
              "        32,  21, 118,   4, 315,   2, 103,  35,   4, 316,  23,   3, 318,\n",
              "       319,  26,   9, 320,   7, 321,  20,   3,  85,   2, 117, 322,   2,\n",
              "         1,  10,   3, 323,   1, 324,   2,   5,   6,  11,  15, 325,   3,\n",
              "         1, 116,   2,   1,   4, 114, 326, 327,   3,   1,   5,   6,  13,\n",
              "         2,  44,  62,  34,  41,   7,  61, 328,   7,  10,   3,  14,  43,\n",
              "       329,  22, 107, 330,  73, 331,  14,   5,   6,  11,  15, 332,  15,\n",
              "       333,   7, 334, 335,  12], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> This will be a Multi-Class Classification problem"
      ],
      "metadata": {
        "id": "VJfcRuwCTNUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8_h_fA2S2X9",
        "outputId": "f36e4ca8-e7ee-43dc-df46-b25e4581c893"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(811, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otNSHKj4ToJg",
        "outputId": "1e918bbd-edd5-4c9c-ae3c-321099a15872"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(811,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhZ3onzdUMn9",
        "outputId": "5457633b-2fdd-4d72-d6f8-eaa169f15c45"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "336"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y, num_classes=337)    # added 1 to the # of words because OneHot Encoding starts with zero but tokenization starts from 1"
      ],
      "metadata": {
        "id": "5jrwTu7bTtVV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDwzdDw8UIC9",
        "outputId": "bf246354-3de3-489c-f3e6-adb0f51af5cc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(811, 337)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense,Embedding,LSTM\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "aEZT4x-6Uy8G"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture: Embedding -> LSTM -> Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(337, 100, input_shape=(19, )))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(337, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsQ0QPQfUdgv",
        "outputId": "25fe975f-d03f-42d7-858b-4345fdda9fce"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "FkBOElJwVZwC",
        "outputId": "333a271c-a3d6-4f56-b7a5-148bb3236012"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m33,700\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m337\u001b[0m)            │        \u001b[38;5;34m50,887\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,700</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">337</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,887</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,187\u001b[0m (918.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,187</span> (918.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,187\u001b[0m (918.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,187</span> (918.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Nez1SOa8Va0r"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x, y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVa_VdYdVkbp",
        "outputId": "d3536792-a17e-4a19-c0b4-bcdc0abd5b17"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.0361 - loss: 5.7328\n",
            "Epoch 2/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0574 - loss: 5.1201\n",
            "Epoch 3/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0709 - loss: 4.9648\n",
            "Epoch 4/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0606 - loss: 4.9845\n",
            "Epoch 5/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0754 - loss: 4.8997\n",
            "Epoch 6/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1187 - loss: 4.8570\n",
            "Epoch 7/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1303 - loss: 4.7198\n",
            "Epoch 8/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1571 - loss: 4.6178\n",
            "Epoch 9/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1830 - loss: 4.4404\n",
            "Epoch 10/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1799 - loss: 4.2851\n",
            "Epoch 11/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2173 - loss: 4.0171\n",
            "Epoch 12/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2253 - loss: 3.8989\n",
            "Epoch 13/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2590 - loss: 3.6756\n",
            "Epoch 14/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2895 - loss: 3.5241\n",
            "Epoch 15/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3204 - loss: 3.3209\n",
            "Epoch 16/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3140 - loss: 3.2100\n",
            "Epoch 17/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3565 - loss: 2.9687\n",
            "Epoch 18/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4045 - loss: 2.7283\n",
            "Epoch 19/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4136 - loss: 2.6531\n",
            "Epoch 20/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4572 - loss: 2.4914\n",
            "Epoch 21/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4861 - loss: 2.3534\n",
            "Epoch 22/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5031 - loss: 2.2066\n",
            "Epoch 23/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5412 - loss: 2.0807\n",
            "Epoch 24/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5614 - loss: 1.9713\n",
            "Epoch 25/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6094 - loss: 1.8516\n",
            "Epoch 26/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6509 - loss: 1.7830\n",
            "Epoch 27/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6985 - loss: 1.6405\n",
            "Epoch 28/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7179 - loss: 1.5764\n",
            "Epoch 29/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7314 - loss: 1.4858\n",
            "Epoch 30/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7651 - loss: 1.3398\n",
            "Epoch 31/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 1.2364\n",
            "Epoch 32/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8385 - loss: 1.1440\n",
            "Epoch 33/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8335 - loss: 1.0967\n",
            "Epoch 34/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8672 - loss: 1.0403\n",
            "Epoch 35/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8883 - loss: 0.9673\n",
            "Epoch 36/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8864 - loss: 0.9333\n",
            "Epoch 37/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8848 - loss: 0.8479\n",
            "Epoch 38/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.8067\n",
            "Epoch 39/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9165 - loss: 0.7594\n",
            "Epoch 40/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9238 - loss: 0.7076\n",
            "Epoch 41/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9129 - loss: 0.7042\n",
            "Epoch 42/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9269 - loss: 0.6610\n",
            "Epoch 43/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.5720\n",
            "Epoch 44/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9388 - loss: 0.5391\n",
            "Epoch 45/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9468 - loss: 0.5284\n",
            "Epoch 46/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.4975\n",
            "Epoch 47/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9576 - loss: 0.4579\n",
            "Epoch 48/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9613 - loss: 0.4447\n",
            "Epoch 49/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.4357\n",
            "Epoch 50/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9483 - loss: 0.4169\n",
            "Epoch 51/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9710 - loss: 0.3747\n",
            "Epoch 52/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9526 - loss: 0.3757\n",
            "Epoch 53/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9552 - loss: 0.3809\n",
            "Epoch 54/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9638 - loss: 0.3232\n",
            "Epoch 55/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9665 - loss: 0.3052\n",
            "Epoch 56/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.3037\n",
            "Epoch 57/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.2649\n",
            "Epoch 58/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9728 - loss: 0.2786\n",
            "Epoch 59/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9643 - loss: 0.2691\n",
            "Epoch 60/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9530 - loss: 0.2708\n",
            "Epoch 61/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9558 - loss: 0.2622\n",
            "Epoch 62/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9652 - loss: 0.2396\n",
            "Epoch 63/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9701 - loss: 0.2251\n",
            "Epoch 64/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9669 - loss: 0.2323\n",
            "Epoch 65/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9765 - loss: 0.2052\n",
            "Epoch 66/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9686 - loss: 0.2072\n",
            "Epoch 67/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.1912\n",
            "Epoch 68/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9716 - loss: 0.1897\n",
            "Epoch 69/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9750 - loss: 0.1797\n",
            "Epoch 70/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9656 - loss: 0.1914\n",
            "Epoch 71/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.1844\n",
            "Epoch 72/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.1970\n",
            "Epoch 73/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9550 - loss: 0.1913\n",
            "Epoch 74/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9570 - loss: 0.1853\n",
            "Epoch 75/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.1658\n",
            "Epoch 76/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9625 - loss: 0.1676\n",
            "Epoch 77/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9559 - loss: 0.1667\n",
            "Epoch 78/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9706 - loss: 0.1484\n",
            "Epoch 79/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.1594\n",
            "Epoch 80/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.1381\n",
            "Epoch 81/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9601 - loss: 0.1462\n",
            "Epoch 82/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.1207\n",
            "Epoch 83/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9653 - loss: 0.1440\n",
            "Epoch 84/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9743 - loss: 0.1227\n",
            "Epoch 85/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9617 - loss: 0.1259\n",
            "Epoch 86/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.1297\n",
            "Epoch 87/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9691 - loss: 0.1236\n",
            "Epoch 88/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9589 - loss: 0.1448\n",
            "Epoch 89/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.1204\n",
            "Epoch 90/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9677 - loss: 0.1227\n",
            "Epoch 91/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9596 - loss: 0.1310\n",
            "Epoch 92/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9642 - loss: 0.1149\n",
            "Epoch 93/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9770 - loss: 0.0953\n",
            "Epoch 94/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9486 - loss: 0.1328\n",
            "Epoch 95/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9701 - loss: 0.0977\n",
            "Epoch 96/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9689 - loss: 0.1007\n",
            "Epoch 97/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9603 - loss: 0.1254\n",
            "Epoch 98/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9619 - loss: 0.1114\n",
            "Epoch 99/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9688 - loss: 0.1045\n",
            "Epoch 100/100\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9638 - loss: 0.1159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ohc60d3wXkkH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "text=\"The internet\"\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "  # Padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=19, padding='pre')\n",
        "\n",
        "  # Predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))    # 11th word is the predicted word\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sv4VeyYWirt",
        "outputId": "6a552b93-70b3-449d-8f8f-ca0abbd0afdc"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "The internet in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "The internet in and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "The internet in and digital\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "The internet in and digital media\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "The internet in and digital media intermediary\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "The internet in and digital media intermediary guidelines\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "The internet in and digital media intermediary guidelines and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "The internet in and digital media intermediary guidelines and services\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "The internet in and digital media intermediary guidelines and services the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "The internet in and digital media intermediary guidelines and services the government\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_token_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYu6U7JFW2Rm",
        "outputId": "8ca976ff-83e9-48aa-bec7-81b904ff5fb4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}